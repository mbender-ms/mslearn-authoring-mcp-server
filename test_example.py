#!/usr/bin/env python3
"""
Test script for Microsoft Style Guide MCP Server

This script tests the MCP server functionality with various content samples
to ensure the analyzer works correctly.
"""

import asyncio
import json
import sys
import time
from pathlib import Path
from typing import Dict, Any

# Add the current directory to the path so we can import our modules
sys.path.insert(0, str(Path(__file__).parent))

try:
    from mcp_client import MicrosoftStyleGuideClient
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("Please ensure mcp_client.py is in the same directory")
    sys.exit(1)

# Test content samples representing different quality levels
TEST_CONTENT = {
    "excellent_example": """
    Welcome to our new feature! You can easily set up your account in just a few steps.
    
    Here's how to get started:
    1. Sign in to your account
    2. Go to Settings  
    3. Choose your preferences
    4. Save your changes
    
    We're here to help if you need assistance. Contact our support team anytime!
    """,
    
    "good_example": """
    This guide shows you how to configure the application settings.
    
    To update your preferences:
    - Open the Settings menu
    - Select the options you want
    - Click Save when you're done
    
    You can change these settings later if needed.
    """,
    
    "needs_improvement": """
    The utilization of this functionality can be leveraged to facilitate the implementation 
    of advanced configurations which might be considered by users who are perhaps interested 
    in exploring the various options that are available to them through the interface that 
    has been provided for their convenience and usage in the context of their specific 
    requirements and use-cases.
    
    Users should be advised that the configuration of the settings might require careful 
    consideration of the implications that could potentially affect the performance of the 
    system in ways that may or may not be immediately apparent to the end-user.
    """,
    
    "accessibility_issues": """
    Hey guys, this is a crazy new feature that will blow your mind! The master configuration 
    controls the slave processes. You'll need to whitelist the trusted sources and blacklist 
    the malicious ones. This is insane - the performance improvements are off the charts!
    
    Obviously, you should utilize this functionality to facilitate optimal performance. 
    The user should simply leverage the advanced settings to achieve the desired results.
    """,
    
    "terminology_issues": """
    To setup your e-mail account, go to the web-site and login to your account. 
    You can configure the A.I. settings and setup automatic backups. The WiFi connection 
    should be stable for real time synchronization.
    
    The API endpoints are available on-line for developers who want to integrate 
    with our web service. Contact the administrator for user-name and password details.
    """,
    
    "grammar_issues": """
    The settings can be configured by the user in the admin panel. The configuration 
    will be saved by the system automatically. Users should be aware that the settings 
    might be overridden by the administrator.
    
    When the application is started by the user, the default settings will be loaded by 
    the system. These settings can be modified by the user if needed. The changes will 
    be applied by the system immediately.
    """
}

class TestRunner:
    """Runs comprehensive tests on the Microsoft Style Guide MCP Server."""
    
    def __init__(self):
        """Initialize the test runner."""
        self.client = MicrosoftStyleGuideClient()
        self.test_results = []
        self.server_path = None
    
    async def setup(self) -> bool:
        """Set up the test environment."""
        print("üîß Setting up test environment...")
        
        # Find the server script
        possible_paths = ["mcp_server.py", "./mcp_server.py"]
        for path in possible_paths:
            if Path(path).exists():
                self.server_path = path
                break
        
        if not self.server_path:
            print("‚ùå Could not find mcp_server.py")
            return False
        
        # Connect to server
        print(f"üîå Connecting to server: {self.server_path}")
        if not await self.client.connect(self.server_path):
            print("‚ùå Failed to connect to MCP server")
            return False
        
        print("‚úÖ Test environment ready")
        return True
    
    async def teardown(self):
        """Clean up test environment."""
        if self.client:
            await self.client.disconnect()
        print("üßπ Test environment cleaned up")
    
    async def run_test(self, test_name: str, test_func, *args, **kwargs) -> Dict[str, Any]:
        """Run a single test and record results."""
        print(f"\nüß™ Running test: {test_name}")
        print("-" * 50)
        
        start_time = time.time()
        try:
            result = await test_func(*args, **kwargs)
            duration = time.time() - start_time
            
            test_result = {
                "name": test_name,
                "status": "PASS" if result.get("success", False) else "FAIL",
                "duration": round(duration, 2),
                "details": result
            }
            
            if test_result["status"] == "PASS":
                print(f"‚úÖ {test_name} - PASSED ({duration:.2f}s)")
            else:
                print(f"‚ùå {test_name} - FAILED ({duration:.2f}s)")
                print(f"   Error: {result.get('error', 'Unknown error')}")
            
            self.test_results.append(test_result)
            return test_result
            
        except Exception as e:
            duration = time.time() - start_time
            print(f"‚ùå {test_name} - EXCEPTION ({duration:.2f}s)")
            print(f"   Exception: {str(e)}")
            
            test_result = {
                "name": test_name,
                "status": "EXCEPTION", 
                "duration": round(duration, 2),
                "details": {"error": str(e)}
            }
            self.test_results.append(test_result)
            return test_result
    
    async def test_server_connection(self) -> Dict[str, Any]:
        """Test basic server connection."""
        # Server should already be connected from setup
        return {"success": True, "message": "Server connection successful"}
    
    async def test_style_guidelines(self) -> Dict[str, Any]:
        """Test style guidelines retrieval."""
        categories = ["voice", "grammar", "terminology", "accessibility", "all"]
        results = {}
        
        for category in categories:
            result = await self.client.get_style_guidelines(category)
            results[category] = result["success"]
            if not result["success"]:
                return {"success": False, "error": f"Failed to get {category} guidelines"}
        
        return {"success": True, "results": results}
    
    async def test_content_analysis(self) -> Dict[str, Any]:
        """Test content analysis with different types."""
        analysis_types = ["comprehensive", "voice_tone", "grammar", "terminology", "accessibility"]
        test_text = TEST_CONTENT["good_example"]
        results = {}
        
        for analysis_type in analysis_types:
            result = await self.client.analyze_content(test_text, analysis_type)
            results[analysis_type] = result["success"]
            if not result["success"]:
                return {"success": False, "error": f"Failed {analysis_type} analysis"}
        
        return {"success": True, "results": results}
    
    async def test_excellent_content(self) -> Dict[str, Any]:
        """Test analysis of excellent content."""
        result = await self.client.analyze_content(TEST_CONTENT["excellent_example"], "comprehensive")
        
        if not result["success"]:
            return result
        
        # Parse the result to check scores
        try:
            # Extract JSON from the result
            result_text = result["result"]
            if "Detailed Analysis:" in result_text:
                json_part = result_text.split("Detailed Analysis:\n")[1]
                analysis_data = json.loads(json_part)
                
                # Check voice tone scores (should be high for excellent content)
                voice_scores = analysis_data.get("voice_tone", {})
                avg_score = sum(v.get("score", 0) for v in voice_scores.values()) / max(1, len(voice_scores))
                
                # Check issue counts (should be low)
                total_issues = (
                    analysis_data.get("grammar", {}).get("total_issues", 0) +
                    analysis_data.get("terminology", {}).get("total_issues", 0) +
                    analysis_data.get("accessibility", {}).get("total_issues", 0)
                )
                
                return {
                    "success": True,
                    "avg_voice_score": avg_score,
                    "total_issues": total_issues,
                    "message": f"Average voice score: {avg_score:.1f}, Total issues: {total_issues}"
                }
            else:
                return {"success": True, "message": "Analysis completed (format not parsed)"}
                
        except json.JSONDecodeError:
            return {"success": True, "message": "Analysis completed (JSON not parseable)"}
    
    async def test_poor_content(self) -> Dict[str, Any]:
        """Test analysis of content that needs improvement."""
        result = await self.client.analyze_content(TEST_CONTENT["needs_improvement"], "comprehensive")
        
        if not result["success"]:
            return result
        
        # Poor content should have identified issues
        try:
            result_text = result["result"]
            if "issues found" in result_text.lower():
                return {"success": True, "message": "Issues correctly identified in poor content"}
            else:
                return {"success": True, "message": "Analysis completed"}
        except:
            return {"success": True, "message": "Analysis completed"}
    
    async def test_accessibility_analysis(self) -> Dict[str, Any]:
        """Test accessibility analysis with problematic content."""
        result = await self.client.analyze_content(TEST_CONTENT["accessibility_issues"], "accessibility")
        
        if not result["success"]:
            return result
        
        # Should identify accessibility issues
        try:
            result_text = result["result"]
            if any(term in result_text.lower() for term in ["guys", "master", "slave", "blacklist", "whitelist", "crazy"]):
                return {"success": True, "message": "Accessibility issues correctly identified"}
            else:
                return {"success": True, "message": "Accessibility analysis completed"}
        except:
            return {"success": True, "message": "Accessibility analysis completed"}
    
    async def test_terminology_analysis(self) -> Dict[str, Any]:
        """Test terminology analysis with incorrect terms."""
        result = await self.client.analyze_content(TEST_CONTENT["terminology_issues"], "terminology")
        
        if not result["success"]:
            return result
        
        # Should identify terminology issues
        try:
            result_text = result["result"]
            if any(term in result_text.lower() for term in ["e-mail", "web-site", "a.i.", "wifi", "setup"]):
                return {"success": True, "message": "Terminology issues correctly identified"}
            else:
                return {"success": True, "message": "Terminology analysis completed"}
        except:
            return {"success": True, "message": "Terminology analysis completed"}
    
    async def test_grammar_analysis(self) -> Dict[str, Any]:
        """Test grammar analysis with passive voice content."""
        result = await self.client.analyze_content(TEST_CONTENT["grammar_issues"], "grammar")
        
        if not result["success"]:
            return result
        
        # Should identify passive voice issues
        try:
            result_text = result["result"]
            if "passive" in result_text.lower():
                return {"success": True, "message": "Grammar issues correctly identified"}
            else:
                return {"success": True, "message": "Grammar analysis completed"}
        except:
            return {"success": True, "message": "Grammar analysis completed"}
    
    async def test_improvement_suggestions(self) -> Dict[str, Any]:
        """Test improvement suggestions functionality."""
        result = await self.client.suggest_improvements(TEST_CONTENT["needs_improvement"], "all")
        
        if not result["success"]:
            return result
        
        # Should provide suggestions
        try:
            result_text = result["result"]
            if "suggestions" in result_text.lower():
                return {"success": True, "message": "Improvement suggestions generated"}
            else:
                return {"success": True, "message": "Improvement analysis completed"}
        except:
            return {"success": True, "message": "Improvement analysis completed"}
    
    async def test_empty_content(self) -> Dict[str, Any]:
        """Test handling of empty content."""
        result = await self.client.analyze_content("", "comprehensive")
        
        # Should handle empty content gracefully
        if result["success"] or "no text" in result.get("error", "").lower():
            return {"success": True, "message": "Empty content handled correctly"}
        else:
            return {"success": False, "error": "Failed to handle empty content"}
    
    async def test_file_analysis(self) -> Dict[str, Any]:
        """Test file analysis functionality."""
        # Create a temporary test file
        test_file = Path("temp_test.md")
        try:
            with open(test_file, "w", encoding="utf-8") as f:
                f.write(TEST_CONTENT["good_example"])
            
            # Import VSCode interface
            from mcp_client import VSCodeInterface
            vscode = VSCodeInterface(self.client)
            
            result = await vscode.analyze_file(str(test_file))
            
            return result if result["success"] else {"success": False, "error": result.get("error")}
            
        except Exception as e:
            return {"success": False, "error": str(e)}
        finally:
            # Clean up test file
            if test_file.exists():
                test_file.unlink()
    
    async def run_all_tests(self):
        """Run all tests and generate a report."""
        print("üöÄ Microsoft Style Guide MCP Server Test Suite")
        print("=" * 70)
        
        # Test suite
        tests = [
            ("Server Connection", self.test_server_connection),
            ("Style Guidelines", self.test_style_guidelines),
            ("Content Analysis Types", self.test_content_analysis),
            ("Excellent Content", self.test_excellent_content),
            ("Poor Content", self.test_poor_content),
            ("Accessibility Analysis", self.test_accessibility_analysis),
            ("Terminology Analysis", self.test_terminology_analysis),
            ("Grammar Analysis", self.test_grammar_analysis),
            ("Improvement Suggestions", self.test_improvement_suggestions),
            ("Empty Content Handling", self.test_empty_content),
            ("File Analysis", self.test_file_analysis)
        ]
        
        # Run all tests
        for test_name, test_func in tests:
            await self.run_test(test_name, test_func)
        
        # Generate summary report
        self.generate_test_report()
    
    def generate_test_report(self):
        """Generate and display test results summary."""
        print("\n" + "=" * 70)
        print("üìä TEST RESULTS SUMMARY")
        print("=" * 70)
        
        total_tests = len(self.test_results)
        passed_tests = len([t for t in self.test_results if t["status"] == "PASS"])
        failed_tests = len([t for t in self.test_results if t["status"] == "FAIL"])
        exception_tests = len([t for t in self.test_results if t["status"] == "EXCEPTION"])
        
        print(f"üìà Total Tests: {total_tests}")
        print(f"‚úÖ Passed: {passed_tests}")
        print(f"‚ùå Failed: {failed_tests}")
        print(f"‚ö†Ô∏è  Exceptions: {exception_tests}")
        print(f"üìä Success Rate: {(passed_tests/total_tests)*100:.1f}%")
        
        total_duration = sum(t["duration"] for t in self.test_results)
        print(f"‚è±Ô∏è  Total Duration: {total_duration:.2f}s")
        
        # Show failed tests
        if failed_tests > 0 or exception_tests > 0:
            print(f"\n‚ùå FAILED/EXCEPTION TESTS:")
            for test in self.test_results:
                if test["status"] in ["FAIL", "EXCEPTION"]:
                    print(f"   ‚Ä¢ {test['name']}: {test['details'].get('error', 'Unknown error')}")
        
        # Overall assessment
        print(f"\nüéØ OVERALL ASSESSMENT:")
        if passed_tests == total_tests:
            print("‚úÖ ALL TESTS PASSED - MCP Server is working perfectly!")
        elif passed_tests >= total_tests * 0.8:
            print("‚úÖ MOSTLY WORKING - Minor issues detected")
        elif passed_tests >= total_tests * 0.6:
            print("‚ö†Ô∏è  PARTIALLY WORKING - Several issues need attention")
        else:
            print("‚ùå MAJOR ISSUES - Server needs significant fixes")
        
        print("\nüéâ Test suite completed!")
        print("=" * 70)

async def main():
    """Main function for running tests."""
    if len(sys.argv) > 1 and sys.argv[1] in ["--help", "-h"]:
        print("""
Microsoft Style Guide MCP Server Test Suite

Usage:
  python test_example.py          # Run all tests
  python test_example.py --help   # Show this help

This script tests the MCP server functionality including:
‚Ä¢ Server connection and basic functionality
‚Ä¢ Style guidelines retrieval
‚Ä¢ Content analysis (all types)
‚Ä¢ Voice and tone analysis
‚Ä¢ Grammar and style checking  
‚Ä¢ Terminology consistency
‚Ä¢ Accessibility and bias checking
‚Ä¢ Improvement suggestions
‚Ä¢ File analysis
‚Ä¢ Error handling

Requirements:
‚Ä¢ mcp_server.py and mcp_client.py in the same directory
‚Ä¢ All dependencies installed (pip install -r requirements.txt)
‚Ä¢ Python 3.8 or higher
        """)
        return
    
    tester = TestRunner()
    
    try:
        # Setup test environment
        if not await tester.setup():
            print("‚ùå Failed to set up test environment")
            return 1
        
        # Run all tests
        await tester.run_all_tests()
        
        # Determine exit code based on results
        failed_count = len([t for t in tester.test_results 
                          if t["status"] in ["FAIL", "EXCEPTION"]])
        
        return 0 if failed_count == 0 else 1
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Tests interrupted by user")
        return 1
    except Exception as e:
        print(f"\n\n‚ùå Test suite failed with error: {e}")
        return 1
    finally:
        await tester.teardown()

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    print(f"\nüèÅ Test suite finished with exit code: {exit_code}")
    sys.exit(exit_code)