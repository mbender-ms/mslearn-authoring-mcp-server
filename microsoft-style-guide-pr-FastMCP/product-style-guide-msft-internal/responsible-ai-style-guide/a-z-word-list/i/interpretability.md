---
title: interpretability - Responsible AI Style Guide
description: Learn how to refer to "interpretability" in your content.
ms.date: 11/13/2024
ms.topic: contributor-guide
ms.service: microsoft-product-style-guide
ms.custom:
  - TopicID 60697
---


# interpretability

You may sometimes see the terms _interpretability_, [_explainability_](~\responsible-ai-style-guide\a-z-word-list\e\explainability.md), and [_intelligibility_](~\responsible-ai-style-guide\a-z-word-list\i\intelligibility.md) used interchangeably. While there is lack of consensus in the research literature about each term’s precise meaning, we recommend the following:

**Use the comprehensive term _intelligibility_ for clarity and consistency in communication and marketing content, especially when emphasizing human understanding.** Use _interpretability_ only when referring specifically to technical properties of an ML model (for example: “Model interpretability can help data scientists debug their models by examining the global impact of each feature on model predictions.”). 

Note, the term _interpretability_ is often used in the context of simple models with parameters that can be inspected (e.g., linear models, small decision trees), in contrast to more complex models like neural networks; simple models are viewed as inherently _interpretable_. Interpretable models can be a way to achieve [_intelligibility_](~\responsible-ai-style-guide\a-z-word-list\i\intelligibility.md) by enabling visibility into the technical workings of the model or system.