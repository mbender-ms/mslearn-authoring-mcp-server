---
title: Focus discussion of AI fairness on fairness-related harms - Responsible AI Style Guide
description: Explore how to address AI fairness by focusing on fairness-related harms. Learn to identify specific types of harms relevant to AI systems and understand their impact on stakeholders.
ms.date: 12/13/2022
ms.topic: contributor-guide
ms.service: microsoft-product-style-guide
ms.custom:
  - TopicID 60770
---


# Focus discussion of AI fairness on fairness-related harms

Because of the variety of reasons an AI system can exhibit unfairness, focus discussion of AI fairness issues by using the language and framework of [fairness-related harms](~\responsible-ai-style-guide\fairness\related-harms\fairness-related-harms.md).  

- Be specific about which [types of fairness-related harms](~\responsible-ai-style-guide\fairness\related-harms\five-types-of-fairness-related-harms.md) are relevant to an AI system.
- Name the various harms a system can exhibit for each stakeholder group who will use or be affected by an AI system.

Be clear that:

- **Different types of fairness-related harm are not mutually exclusive;** a single AI system can exhibit more than one type.
- **Fairness-related harms can arise at any stage** of the [AI development and deployment life cycle](~\responsible-ai-style-guide\a-z-word-list\a\ai-development-and-deployment-life-cycle.md).
- Many AI systems **are subjective even unintentionally** and can **exhibit fairness-related harms unrelated to the intention of the systems’ developers.** 
- **Fairness-related harms can have varying severities,** and the cumulative impact of even “non-severe” harms can be extremely burdensome or make people feel singled out or undervalued. 
- **Prioritizing fairness in AI systems often means making tradeoffs** based on competing priorities (e.g., resource constraints may need to be balanced with fairness considerations); there are seldom clear-cut answers.  