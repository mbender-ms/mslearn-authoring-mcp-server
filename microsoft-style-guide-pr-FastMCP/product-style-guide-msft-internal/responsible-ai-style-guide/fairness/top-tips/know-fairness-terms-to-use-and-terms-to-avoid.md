---
title: Know fairness terms to use and terms to avoid - Responsible AI Style Guide
description: Learn the appropriate terminology to use when discussing fairness in AI systems. Understand which terms to avoid and why, and discover how to effectively communicate about fairness-related harms.
ms.date: 12/13/2022
ms.topic: contributor-guide
ms.service: microsoft-product-style-guide
ms.custom:
  - TopicID 60766
---


# Know fairness terms to use and terms to avoid

**Use**

**Use _fairness issues_** as a term to describe when an AI system exhibits unwanted, unfair behaviors. Fairness issues may result in [fairness-related harms](~\responsible-ai-style-guide\fairness\related-harms\fairness-related-harms.md) to various groups of people.

**Use _demean_ or _demeaning_ instead of _denigrate, denigrating, denigration._** In the context of discussing fairness-related harms, avoid using the terms _denigrate_ or harms of _denigration_. Instead use _demean_ or harms of _demeaning_. (There are racial inequalities tied to the etymology of denigration, which references the act of making or becoming black, darkening, or discoloring.)

**Avoid**

**Avoid using _bias, AI bias,_ or _algorithmic bias_**, which are often used as catchphrase terms for fairness issues, [fairness-related harms](~\responsible-ai-style-guide\fairness\related-harms\fairness-related-harms.md) and their causes, and more.

- **Don’t use the word _bias_ on its own.** Always qualify the type of bias you are referring to (e.g., statistical bias, societal bias, cognitive bias, confirmation bias). Use the complete term _statistical bias_ or _societal bias_ when referring to these specific phenomena. When the intention is to communicate about _societal bias,_ consider naming specifics, such as racism, sexism, ageism, or transphobia.

**Avoid using language that claims or implies “de-biasing” of AI systems or “guaranteeing” fairness.** It is not possible to fully “de-bias” an AI system. Instead, emphasize that teams tasked with developing and deploying AI systems should work to **identify, measure, and mitigate** fairness-related harms as much as possible. See [Talking about measuring fairness-related harms](~\responsible-ai-style-guide\fairness\related-harms\talking-about-measuring-fairness-related-harms.md) and [Talking about mitigating fairness-related harms](~\responsible-ai-style-guide\fairness\related-harms\talking-about-mitigating-fairness-related-harms.md).

**Terms quick reference**

| **Use this**                                                                                                                                  | **Not this**                                                                                     |
|----------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| _fairness issues_, to describe when an AI system exhibits unwanted, unfair behaviors                                                         | biased                                                                                           |
| demean, demeaning                                                                                                                            | denigrate, denigrating, denigration                                                              |
| statistical bias, societal bias, cognitive bias, confirmation bias                                                                           | bias, AI bias, algorithmic bias                                                                  |
| _Teams tasked with developing and deploying AI systems_ _should work to_ **identify, measure, and mitigate fairness-related harms**.         | de-bias, bias-free, de-biased, unbiased, neutral, guarantee fairness, solve for fairness, fix fairness |