---
title: Fairness in AI - Responsible AI Style Guide
description: Explore how to effectively communicate about fairness in AI systems. Learn to address misunderstandings and misconceptions with precision, and discover guidance on discussing fairness-related harms and demographic language.
ms.date: 10/02/2023
ms.topic: contributor-guide
ms.service: microsoft-product-style-guide
ms.custom:
  - TopicID 60763
---


# Fairness in AI

## How we talk about fairness in AI matters

Fairness in AI is a complex topic. AI systems [can behave unfairly for a variety of reasons](~\responsible-ai-style-guide\fairness\top-tips\communicate-that-ai-systems-can-behave-unfairly.md), resulting in [fairness-related harms](~\responsible-ai-style-guide\fairness\related-harms\fairness-related-harms.md) for some individuals or [groups of people](~\responsible-ai-style-guide\fairness\experiences\who-experiences-fairness-related-harms.md).  

There are many definitions of fairness, both quantitative and qualitative. There are also many causes of unfairness in AI systems and many approaches to measuring and mitigating unfairness, yet there are no perfect solutions. 

As is often the case with complex topics, there are misunderstandings and misconceptions. By talking about fairness in AI with rigor and precision, we avoid contributing to confusion. The following guidance empowers you to communicate accurately about fairness in AI systems.

- [Top tips for talking about fairness in AI](~\responsible-ai-style-guide\fairness\top-tips\top-tips-for-talking-about-fairness-in-ai.md)
- [Fairness-related harms](~\responsible-ai-style-guide\fairness\related-harms\fairness-related-harms.md)
- [Who experiences fairness-related harms](~\responsible-ai-style-guide\fairness\experiences\who-experiences-fairness-related-harms.md)
- [Demographics language: How to talk about groups of people.](~\responsible-ai-style-guide\fairness\demographics-language\demographics-language-how-to-talk-about-groups-of-people.md)