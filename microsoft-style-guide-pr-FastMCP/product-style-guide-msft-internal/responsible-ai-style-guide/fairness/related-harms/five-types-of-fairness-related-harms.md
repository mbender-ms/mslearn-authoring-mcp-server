---
title: Five types of fairness-related harms - Responsible AI Style Guide
description: Explore the five types of fairness-related harms in AI systems as categorized by Microsoft. Understand how these harms, including quality-of-service, allocation, stereotyping, demeaning, and over- and underrepresentation, can impact AI outcomes. Learn to identify and name specific harms to improve AI fairness and inclusivity.
ms.date: 12/13/2022
ms.topic: contributor-guide
ms.service: microsoft-product-style-guide
ms.custom:
  - TopicID 60774
---


# Five types of fairness-related harms

Microsoft categorizes AI fairness-related harms into five types: quality-of-service harms; allocation harms; and three representational harms—stereotyping, demeaning, and over- and underrepresentation.

- **Quality-of-service harms:** When an AI system does not work as well for one group of people as it does for another. 
- **Allocation harms:** When an AI system extends or withholds opportunities or resources in ways that negatively impact people’s lives.
- **Stereotyping harms:** When an AI system makes unfair generalizations about groups of people and reinforces negative stereotypes.
- **Demeaning harms:** When an AI system is actively derogatory or offensive.
- **Over- and underrepresentation harms:** When an AI system over- or underrepresents some groups of people—or may even erase some groups entirely.

**Note:** A single AI system **may exhibit more than one type of harm,** as shown below.

![Image](~/media/2086666516.png)

When possible, **name the specific harms that are relevant to the AI system:**

| **Use this** | **Not this** |
|--------------|--------------|
| The research paper revealed the **quality-of-service harms** exhibited in many large facial recognition systems. | The research paper revealed biased outcomes exhibited in many large facial recognition systems. |
| While this system works well for some groups, it’s known that women with darker skin color are **underrepresented** in the training data and experience **quality-of-service harms** when interacting with facial recognition systems. | Some groups may face issues using facial recognition systems as well as others. |