---
title: Talking about how and when harms can be introduced - Responsible AI Style Guide
description: Learn how fairness-related harms can be introduced at any stage of the AI development and deployment life cycle. Understand the impact of societal biases, incorrect assumptions, and team diversity on AI systems.
ms.date: 12/13/2022
ms.topic: contributor-guide
ms.service: microsoft-product-style-guide
ms.custom:
  - TopicID 60775
---


# Talking about how and when harms can be introduced

Communicate that fairness-related **harms can be introduced at any stage** of the [AI development and deployment life cycle](~\responsible-ai-style-guide\a-z-word-list\a\ai-development-and-deployment-life-cycle.md) due to various possibilities, including:

- Societal biases reflected in the content of datasets.
- Incorrect assumptions about what is captured in a dataset. 
- Characteristics of other system components including, but not limited to, task definitions, user experiences, evaluation metrics, and deployment contexts.
- Assumptions made (either explicitly or implicitly) by teams throughout the AI systemâ€™s development and deployment life cycle. 
- Lack of diversity on development teams.  
